+++ 
date = 2022-08-18T20:51:07+08:00
title = "Raft FAQ"
description = ""
slug = ""
authors = []
tags = []
categories = []
externalLink = ""
series = []
+++

## Official FAQ

### What do people use Raft for ?
* The most frequent use for Raft (and Paxos) is to build fault-tolerant "configuration services" whose job is to keep track of how responsibilities are currently assigned to servers in a large deployment. This job is particularly sensitive for deployments with replication; Raft-based configuration services are often used to select primaries in a way that avoids split brain. The VMware FT test-and-set server is a simple example of a configuration service. Chubby, ZooKeeper, and etcd are more powerful fault-tolerant configuration services based on Raft or Paxos; they are widely used.
* Some databases, such as Spanner, CockroachDB, and Lab 3, use Raft or Paxos to replicate the data. (In contrast, GFS, VMware FT, and Chain Replication use simpler primary-backup for the data.) Some databases use Raft or Paxos in two different ways: for the configuration service that assigns responsibilities to servers (for every shard, who is currently primary and who are backups), and separately to handle the data within each shard.

### Does Raft sacrifice anything for simplicity?
Raft gives up some performance in return for clarity; for example:
* batching落盘
* pipelining AppendEntries
* 减小snapshot数据量，只落盘最近更新的部分
* 同理，如果follower已经有落后的snapshot，那没必要发送完整的snapshot
* 由于log的顺序约束，每次只执行一个操作，没有充分利用单服务器上的多核处理能力

### Is Raft used in real-world software, or do companies generally roll their own flavor of Paxos (or use a different consensus protocol)?
* There are several real-world users of Raft: [Docker](https://docs.docker.com/engine/swarm/raft/), [etcd](https://etcd.io), and MongoDB. Other systems said to be using Raft include CockroachDB, RethinkDB, and TiKV. Maybe you can find more starting at http://raft.github.io/
* On the other hand, many real-world state-machine replication systems (Google's Chubby, ZooKeeper's ZAB) are derived from the older Multi-Paxos and Viewstamped Replication protocols.

### What is Paxos? In what sense is Raft simpler?
* There is a protocol called Paxos that allows a set of servers to agree on a single value. While Paxos requires some thought to understand, it is far simpler than Raft. Here's an easy-to-read paper about [Paxos](http://css.csail.mit.edu/6.824/2014/papers/paxos-simple.pdf)
* However, Paxos solves a smaller problem than Raft. To build a real-world replicated service, the replicas need to agree on an indefinite sequence of values (the client commands), and they need ways to efficiently recover when servers crash and restart or miss messages. People have built such systems with Paxos as the starting point; look up Google's Chubby and Paxos Made Live papers, and ZooKeeper/ZAB. There is also a protocol called Viewstamped Replication; it's a good design, and similar to Raft, but the paper about it is hard to understand.
* These real-world protocols are complex, and (before Raft) there was not a good introductory paper describing how they work. The Raft paper, in contrast, is relatively easy to read and fairly detailed. That's a big contribution.
* Whether the Raft protocol is inherently easier to understand than something else is not clear. The issue is clouded by a lack of good descriptions of other real-world protocols. In addition, Raft sacrifices performance for clarity in a number of ways; that's fine for a tutorial but not always desirable in a real-world protocol.

### How does Raft's performance compare to Paxos in real-world applications?
* The fastest Paxos-derived protocols are probably faster than Raft as described in the paper; have a look at ZAB/ZooKeeper and Paxos Made Live. On the other hand, etcd3 (using Raft) claims to have achieved better performance than zookeeper and many Paxos-based implementations (https://www.youtube.com/watch?v=hQigKX0MxPw).

* There are situations where Raft's leader is not so great. If the datacenters containing replicas and clients are distant from each other, people sometimes use agreement protocols derived from original Paxos. The reason is that Paxos has no leader; any replica can start an agreement; so clients can talk to the replica in their local datacenter rather than having to talk to a leader in a distant datacenter. ePaxos is an example.

### Are there systems like Raft that can survive and continue to operate when only a minority of the cluster is active?
* Not with Raft's properties. But you can do it with different assumptions, or different client-visible semantics. The basic problem is split-brain -- the possibility of multiple diverging copies of the state, caused by multiple subsets of the replicas mutating the state without being aware of each other. There are two solution approaches that I know of.

* If somehow clients and servers can learn exactly which servers are live and which are dead (as opposed to live but unreachable due to network failure), then one can build a system that can function as long as one is alive, picking (say) the lowest-numbered server known to be alive. However, it's usually impractical for one computer to decide if another computer is dead, as opposed to the network losing the messages between them. One way to do it is to have a human decide: the human can inspect the servers and decide which are alive and dead.

* The other approach is to allow split-brain operation, and to have a way for servers to reconcile the resulting diverging state after partitions are healed. This can be made to work for some kinds of services, but has complex client-visible semantics (usually called "eventual consistency"). Have a look at the COPS, FuzzyLog, and Bitcoin papers which are assigned later in the course.

### In Raft, the service which is being replicated is not available to the clients during an election process. In practice how much of a problem does this cause?
* The client-visible pause seems likely to be on the order of a tenth of a second. The authors expect failures (and thus elections) to be rare, since they only happen if machines or the network fails. Many servers and networks stay up continuously for months or even years at a time, so this doesn't seem like a huge problem for many applications.

### Are there other consensus systems that don't have leader-election pauses?
* There are versions of Paxos-based replication that do not have a leader or elections, and thus don't suffer from pauses during elections. Instead, any server can effectively act as leader at any time. The cost of not having a leader is that more messages are required for each agreement.

### Why can't a malicious person take over a Raft server, or forge incorrect Raft messages?
* Raft doesn't include defenses against attacks like this. It assumes that all participants are following the protocol, and that only the correct set of servers is participating.

* A real deployment would have to keep out malicious attackers. The most straightforward option is to place the servers behind a firewall to filter out packets from random people on the Internet, and to ensure that all computers and people inside the firewall are trustworthy.

* There may be situations where Raft has to operate on the same network as potential attackers. In that case a good plan would be to authenticate the Raft packets with some cryptographic scheme. For example, give each legitimate Raft server a public/private key pair, have it sign all the packets it sends, give each server a list of the public keys of legitimate Raft servers, and have the servers ignore packets that aren't signed by a key on that list.

### The paper mentions that Raft works under all non-Byzantine conditions. What are Byzantine conditions and why could they make Raft fail?
* "Non-Byzantine conditions" means that the servers are fail-stop: they either follow the Raft protocol correctly, or they halt. For example, most power failures are non-Byzantine because they cause computers to simply stop executing instructions; if a power failure occurs, Raft may stop operating, but it won't send incorrect results to clients.

* Byzantine failure refers to situations in which some computers execute incorrectly, because of bugs or because someone malicious is controlling the computers. If a failure like this occurs, Raft may send incorrect results to clients.

* Most of 6.824 is about tolerating non-Byzantine faults. Correct operation despite Byzantine faults is more difficult; we'll touch on this topic at the end of the term.

### What if a client sends a request to a leader, but the leader crashes before sending the client request to all followers, and the new leader doesn't have the request in its log? Won't that cause the client request to be lost?
* Yes, the request may be lost. If a log entry isn't committed, Raft may not preserve it across a leader change.

* That's OK because the client could not have received a reply to its request if Raft didn't commit the request. The client will know (by seeing a timeout or leader change) that its request may have been lost, and will re-send it.

* The fact that clients can re-send requests means that the system has to be on its guard against duplicate requests; you'll deal with this in Lab 3.

### If there's a network partition, can Raft end up with two leaders and split brain?
* No. There can be at most one active leader. A new leader can only be elected if it can contact a majority of servers (including itself) with RequestVote RPCs. So if there's a partition, and one of the partitions contains a majority of the servers, that one partition can elect a new leader. Other partitions must have only a minority, so they cannot elect a leader. If there is no majority partition, there will be no leader (until someone repairs the network).

### Suppose a new leader is elected while the network is partitioned, but the old leader is in a different partition. How will the old leader know to stop committing new entries?
* The old leader will either not be able to get a majority of successful responses to its AppendEntries RPCs (if it's in a minority partition), or if it can talk to a majority, that majority must overlap with the new leader's majority, and the servers in the overlap will tell the old leader that there's a higher term. That will cause the old leader to switch to follower.

### What if the election timeout is too short? Will that cause Raft to malfunction?
* A bad choice of election timeout does not affect safety, it only affects liveness.

* If the election timeout is too small, then followers may repeatedly time out before the leader has a chance to send out any AppendEntries. In that case Raft may spend all its time electing new leaders, and no time processing client requests. If the election timeout is too large, then there will be a needlessly large pause after a leader failure before a new leader is elected.

### Why randomize election timeouts?
* To reduce the chance that multiple peers simultaneously become candidates and divide the votes among themselves so that no-one gets a majority.

### Can a candidate declare itself the leader as soon as it receives votes from a majority, and not bother waiting for further RequestVote replies?
* Yes -- a majority is sufficient. It would be a mistake to wait longer, because some peers might have failed and thus not ever reply.

### What network does Raft assume?
* The network is unreliable: it may lose requests and replies and delay them.  Raft's RPC library doesn't provide reliability; it is best effort (e.g,. it sends a request but the network may drop it). The lab's RPC library provides similar semantics: it may lose requests, lose replies, delay messages, and entirely disconnect particular hosts.

### What is the purpose of the votedFor check in the requestVote RPC?
* Two candidates may start an election at the same time for the same new term. A follower should vote only for one of them.

### When are followers' log entries sent to their state machines?
* Only after the leader says that an entry is committed, using the leaderCommit field of the AppendEntries RPC. At that point the follower can execute (or apply) the log entry, which for us means send it on the applyCh.

### What happens if a half (or more) of the servers die?
* The service can't make any progress; it will keep trying to elect a leader over and over. If/when enough servers come back to life with persistent Raft state intact, they will be able to elect a leader and continue.

